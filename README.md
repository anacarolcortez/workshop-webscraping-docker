ğŸ•¸ï¸ Workshop de Web Scraping com Selenium & Python

Bem-vinda ao workshop! Este projeto foi configurado para que vocÃª nÃ£o precise se preocupar com a instalaÃ§Ã£o de Drivers, Chrome ou variÃ¡veis de ambiente. Usaremos o Docker para garantir que tudo funcione perfeitamente no seu computador.

ğŸ“‹ PrÃ©-requisitos

VocÃª sÃ³ precisa de uma coisa instalada:

    Docker Desktop (baixe e instale a versÃ£o para o seu sistema operacional).

    AtenÃ§Ã£o: Certifique-se de que o Docker esteja aberto e rodando antes de comeÃ§ar.

ğŸš€ Como comeÃ§ar
1. Baixe o projeto

FaÃ§a o download do cÃ³digo e abra a pasta na sua IDE (recomendo o VS Code).

2. Prepare o ambiente

No terminal, dentro da pasta do projeto, digite o seguinte comando:

```
docker compose up -d
```

Este comando vai baixar as imagens necessÃ¡rias e preparar os "computadores virtuais" (containers) para o nosso cÃ³digo.

3. Abra o browser do container

ğŸ“º Como o Selenium estÃ¡ rodando dentro de um container, vocÃª nÃ£o verÃ¡ uma janela do Chrome pulando na sua tela. Mas vocÃª pode assistir ao processo por "dentro" do Docker:

    Abra o seu navegador (Chrome, Edge, Firefox...) e digite: http://localhost:7900

    Clique em Connect.

    Se pedir uma senha, digite: secret

    Pronto! VocÃª verÃ¡ a tela do Linux do container onde o Chrome estÃ¡ rodando.

4. Rode o cÃ³digo

Agora, para executar o nosso script de raspagem de dados, rode:

```
docker compose run app poetry run python main.py
```

VÃ¡ ao browser do container e veja o navegador sendo comandado ao vivo pelo Selenium :)

ğŸ› ï¸ Comandos Ãšteis

    Para parar tudo: docker-compose down

    Para reinstalar uma biblioteca nova (Poetry): Se vocÃª adicionar algo no pyproject.toml, rode: docker-compose build app

ğŸ“ O que vamos aprender?

* Como navegar em pÃ¡ginas dinÃ¢micas.

* Como encontrar elementos (botÃµes, inputs, textos).

* Como lidar com esperas implÃ­citas e explÃ­citas.

* Boas prÃ¡ticas para nÃ£o ser bloqueada.

Para este workshop, vamos usar como exemplo o site da Imprensa Nacional, o DiÃ¡rio Oficial da UniÃ£o.

Vamos fazer uma busca pela palavra-chave "materiais didÃ¡ticos", e usar filtros para selecionar contratos firmados com o MinistÃ©rio da EducaÃ§Ã£o em 2025.

Vamos salvar as informaÃ§Ãµes de cada contrato obtido em um arquivo no formato csv, ideal para futura anÃ¡lise de dados.

Este exemplo Ã© bem interessante porque traz todos os exemplos necessÃ¡rios para webscraping em qualquer site, como captura de elementos no DOM do HTML, interaÃ§Ã£o com eles (clicar, inserir textos, mudar de pÃ¡gina, copiar texto).

Na pasta "conteudo" deste repositÃ³rio, apresento o cÃ³digo que vamos escrever no workshop e o csv resultante. Mas o objetivo deste repositÃ³rio Ã© apresentar uma forma simples e genÃ©rica de conseguir rodar o Selenium em qualquer computador por meio de um ambiente virtual. Afinal, o Colab Ã© muito limitado para webscraping, pois costuma ser barrado pelos firewalls dos sites. Para isso, escreva os cÃ³digos do seu projeto no arquivo main.py.